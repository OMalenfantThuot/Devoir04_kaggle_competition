{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Kaggle competition.\n",
    "\"\"\"\n",
    "\n",
    "__authors__ = \"Jimmy Leroux, Nicolas Laliberte, Olivier Malenfant-Thuot,\\\n",
    "    Simon Dufort-LabbÃ©\"\n",
    "__version__ = \"1.0\"\n",
    "__maintainer__ = \"Jimmy Leroux\"\n",
    "__studentid__ = \"1024610, 1005803, 1012818, 0925272\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import csv\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.drop = nn.Dropout2d(p=0.05)\n",
    "        self.dropfc = nn.Dropout(p=0.20)\n",
    "        self.conv1 = nn.Conv2d(1, 128, 3, padding=1) #was 5 96\n",
    "        self.conv2 = nn.Conv2d(128, 128, 3, padding=1)  #44\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1) #22\n",
    "        self.conv4 = nn.Conv2d(256, 256, 3, padding=1)#9\n",
    "        self.conv5 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)        \n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.bn6 = nn.BatchNorm2d(512)\n",
    "        self.bn7 = nn.BatchNorm2d(512)\n",
    "        self.bn8 = nn.BatchNorm1d(1024)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(512 * 5 * 5, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 31)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop((self.bn1(F.relu(self.conv1(x))))) #48\n",
    "        x = self.drop(self.pool(self.bn2(F.relu(self.conv2(x))))) #22\n",
    "        x = self.drop((self.bn3(F.relu(self.conv3(x)))))\n",
    "        x = self.drop(self.pool(self.bn4(F.relu(self.conv4(x)))))\n",
    "        x = self.drop((self.bn5(F.relu(self.conv5(x)))))\n",
    "        x = self.drop(self.pool(self.bn6(F.relu(self.conv6(x)))))\n",
    "        x = self.drop((self.bn7(F.relu(self.conv7(x)))))\n",
    "        x = x.view(-1, 512 * 5 * 5)\n",
    "        x = self.dropfc(self.bn8(F.relu(self.fc1(x))))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class kaggle_dataset(torch.utils.data.dataset.Dataset):\n",
    "    def __init__(self, data, labels, transforms=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        dat = self.data[index]\n",
    "        if self.transforms is not None:\n",
    "            dat = self.transforms(dat)\n",
    "        return (dat,self.labels[index])\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def define_classes(labels):\n",
    "    classes = {}\n",
    "    label = []\n",
    "    c = 0\n",
    "    for i,j in labels:\n",
    "        if j.decode('utf-8') not in classes:\n",
    "            classes[j.decode('utf-8')] = c\n",
    "            c += 1\n",
    "        label.append(classes[j.decode('utf-8')])    \n",
    "    return classes, torch.LongTensor(label)\n",
    "\n",
    "def reshape_images(images):\n",
    "    train_im = []\n",
    "    #noise = torch.zeros(1,100,100)\n",
    "    c = 0\n",
    "    #_,label = define_classes(train_labels)\n",
    "    #for i in range(images.shape[0]):\n",
    "    #    if label[i]==21:\n",
    "    #        noise += torch.Tensor(images[i][1]).reshape((1,100,100)) / 255.\n",
    "    #        c += 1.\n",
    "    #noise /= c   \n",
    "    for i in range(images.shape[0]):\n",
    "        train_im.append(torch.Tensor(images[i][1].reshape((1,40,40))) / 255.)\n",
    "    return train_im\n",
    "\n",
    "def train(images, labels):\n",
    "    \n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToPILImage(), transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),transforms.RandomApply(\n",
    "        [transforms.RandomRotation(10)],0.0),transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = kaggle_dataset(\n",
    "        reshape_images(images)[:9500],define_classes(labels)[1][:9500],\n",
    "            transforms=transform)\n",
    "    \n",
    "    testset = kaggle_dataset(\n",
    "        reshape_images(images)[9500:],define_classes(labels)[1][9500:],\n",
    "            transforms=transform)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "    classes = [str(i) for i in range(31)]\n",
    "    net = Net().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weight(\n",
    "        define_classes(labels)[1][:9500]).to(device))\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01, weight_decay=0.025,\n",
    "        momentum=0.9) #wc was 0.01\n",
    "    \n",
    "    loss_train = []\n",
    "    loss_test = []\n",
    "    err_train = []\n",
    "    err_test = []\n",
    "    for epoch in range(35):  # loop over the dataset multiple times\n",
    "        if epoch>10:\n",
    "            optimizer = optim.SGD(net.parameters(), lr=0.001,\n",
    "                weight_decay=0.025, momentum=0.9) #lr 0.001\n",
    "        if epoch>20: #was30\n",
    "            optimizer = optim.SGD(net.parameters(), lr=0.0005,\n",
    "                weight_decay=0.025, momentum=0.9) \n",
    "        if epoch>30: #was40\n",
    "            optimizer = optim.SGD(net.parameters(), lr=0.0001,\n",
    "                weight_decay=0.025, momentum=0.9)\n",
    "        correct = 0.\n",
    "        total = 0.\n",
    "        running_loss_train = 0.0\n",
    "        running_loss_test = 0.0\n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            \n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs.to(device))\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss.item() / 9500\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "        err_train.append(1 - correct / total)\n",
    "\n",
    "        correct = 0.\n",
    "        total = 0.\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images.to(device))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels.to(device)).sum().item()\n",
    "                loss = criterion(outputs, labels.to(device))\n",
    "                running_loss_test += loss.item() / 500\n",
    "        err_test.append(1 - correct / total)\n",
    "        \n",
    "        loss_train.append(running_loss_train)\n",
    "        loss_test.append(running_loss_test)\n",
    "        print('Epoch: {}'.format(epoch))\n",
    "        print('Train loss: {0:.4f} Train error: {1:.2f}'.format(\n",
    "            loss_train[epoch], err_train[epoch]))\n",
    "        print('Test loss: {0:.4f} Test error: {1:.2f}'.format(\n",
    "            loss_test[epoch], err_test[epoch])) \n",
    "   \n",
    "    print('Finished Training')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(10):\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images.to(device))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 1000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(31))\n",
    "    class_total = list(0. for i in range(31))\n",
    "    net.eval()   \n",
    "    with torch.no_grad():\n",
    "        for i in range(10):\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images.to(device))\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                c = (predicted == labels.to(device)).squeeze()\n",
    "                for i in range(c.shape[0]):\n",
    "                    label = labels[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "    for i in range(31):\n",
    "        if class_total[i]!=0:\n",
    "            print('Accuracy of %5s : %2d %%' % (\n",
    "                classes[i], 100 * class_correct[i]/class_total[i]))\n",
    "        else:\n",
    "            print('Accuracy of %5s : %2d %%' % (\n",
    "                classes[i], 100 * class_correct[i]))\n",
    "    return net, loss_train, loss_test, err_train, err_test\n",
    "\n",
    "def predict(net, datas, classes):\n",
    "    prediction = []\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in datas:\n",
    "            image, dummy = data\n",
    "            outputs = net(image.to(device))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            prediction.extend(predicted.tolist())\n",
    "    with open('submission.csv', mode='w') as submission:\n",
    "        writer = csv.writer(submission, delimiter=',',\n",
    "            quotechar='\"', quoting=csv.QUOTE_MINIMAL)    \n",
    "        for i in range(len(prediction)):\n",
    "            prediction[i] = classes[prediction[i]]\n",
    "            writer.writerow([str(i), prediction[i]])\n",
    "    return prediction\n",
    "\n",
    "def weight(labels):\n",
    "    scale = torch.FloatTensor(31)\n",
    "    for i in range(31):\n",
    "        scale[i] = ((labels==i).sum())\n",
    "    return scale.max() / scale\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.cuda.manual_seed(10)\n",
    "    plt.style.use('ggplot')     \n",
    "    plt.rc('xtick', labelsize=15)\n",
    "    plt.rc('ytick', labelsize=15)\n",
    "    plt.rc('axes', labelsize=15)        \n",
    "    classes = {3:'apple',21:'empty',23:'moustache',6:'mouth',30:'mug',19:'nail',\n",
    "        13:'nose',22:'octagon',24:'paintbrush',25:'panda',26:'parrot',9:'peanut',16:'pear',\n",
    "        20:'pencil',18:'penguin',17:'pillow',5:'pineapple',15:'pool',10:'rabbit',\n",
    "        29:'rhinoceros',1:'rifle',8:'rollerskates',12:'sailboat',2:'scorpion',27:'screwdriver',\n",
    "        0:'shovel',11:'sink',7:'skateboard',14:'skull',4:'spoon',28:'squiggle'}\n",
    "    #images_train = np.load('C:/Users/Jimmy/Desktop/Kaggle/Train_images.npy',\n",
    "    #    encoding='latin1')\n",
    "    \n",
    "    #train_labels = np.genfromtxt('C:/Users/Jimmy/Desktop/Kaggle/train_labels.csv',\n",
    "    #    names=True, delimiter=',', dtype=[('Id', 'i8'), ('Category', 'S5')])\n",
    "    \n",
    "    #images_test = np.load('C:/Users/Jimmy/Desktop/Kaggle/test_images.npy',\n",
    "    #    encoding='latin1')\n",
    "\n",
    "    images_train = np.load(\n",
    "        'C:/Users/Jimmy/Desktop/Kaggle/cleaned_images.npy',\n",
    "        encoding='latin1')\n",
    "    \n",
    "    train_labels = np.genfromtxt(\n",
    "        'C:/Users/Jimmy/Desktop/Kaggle/train_labels.csv',\n",
    "        names=True, delimiter=',', dtype=[('Id', 'i8'), ('Category', 'S5')])\n",
    "    \n",
    "    images_test = np.load('C:/Users/Jimmy/Desktop/Kaggle/cleaned_test_images.npy',\n",
    "        encoding='latin1')\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    images_test = reshape_images(images_test)\n",
    "    \n",
    "    images_test_dataset = kaggle_dataset(\n",
    "        images_test, torch.tensor([0.]*len(images_test)),transforms=transform)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(images_test_dataset, batch_size=64,\n",
    "        shuffle=False, num_workers=0)\n",
    "    t1 = time.time()\n",
    "\n",
    "    net, loss_train, loss_test, e_train, e_test = train(images_train, train_labels)    \n",
    "    prediction = predict(net, test_loader, classes)   \n",
    "    print(time.time()-t1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(1,36),loss_train, 'sk-', label='Train')\n",
    "    plt.plot(range(1,36),loss_test, 'sr-', label='Valid')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Average loss', labelpad=0)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(1,36),e_train, 'sk-', label='Train')\n",
    "    plt.plot(range(1,36),e_test, 'sr-', label='Valid')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error', labelpad=0)\n",
    "    plt.legend()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
