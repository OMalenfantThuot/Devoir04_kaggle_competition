{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p12h3qGEoU2w"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZLsACZ6oU23"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.drop = nn.Dropout2d(p=0.05)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 7, padding=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 5, padding=2)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 256, 2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)        \n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool1 = nn.MaxPool2d(5)\n",
    "        self.pool2 = nn.MaxPool2d(3)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(256 * 3 * 3, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 31)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(F.relu(self.conv1(x)))\n",
    "        x = self.drop(self.pool1(self.bn2(F.relu(self.conv2(x)))))\n",
    "        x = self.bn2(F.relu(self.conv3(x)))\n",
    "        x = self.pool2(self.bn3(F.relu(self.conv4(x))))\n",
    "        x = self.bn3(F.relu(self.conv5(x)))\n",
    "        x = self.pool3(self.bn4(F.relu(self.conv6(x))))\n",
    "        x = x.view(-1, 256 * 3 * 3)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TrkZU04GoU28"
   },
   "outputs": [],
   "source": [
    "class kaggle_dataset(torch.utils.data.dataset.Dataset):\n",
    "    def __init__(self, data, labels, transforms=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        dat = self.data[index]\n",
    "        if self.transforms is not None:\n",
    "            dat = self.transforms(dat)\n",
    "        return (dat,self.labels[index])\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7BllFvotoU3A"
   },
   "outputs": [],
   "source": [
    "def define_classes(labels):\n",
    "    classes = {}\n",
    "    label = []\n",
    "    c = 0\n",
    "    for i,j in labels:\n",
    "        if j.decode('utf-8') not in classes:\n",
    "            classes[j.decode('utf-8')] = c\n",
    "            c += 1\n",
    "        label.append(classes[j.decode('utf-8')])    \n",
    "    return classes, torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nX46cqDVoU3E"
   },
   "outputs": [],
   "source": [
    "def reshape_images(images):\n",
    "    train_im = [] \n",
    "    for i in range(images.shape[0]):\n",
    "        train_im.append(torch.Tensor(images[i][1].reshape((1,100,100)).copy()) / 255.)\n",
    "    return train_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lru9jz3BoU3I"
   },
   "outputs": [],
   "source": [
    "def train(images, labels, nepochs):\n",
    "    \n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToPILImage(), transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        \n",
    "#     transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(),\n",
    "#          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = kaggle_dataset(\n",
    "        reshape_images(images)[:55000],define_classes(labels)[1][:55000],\n",
    "        transforms=transform)\n",
    "    \n",
    "    testset = kaggle_dataset(\n",
    "        reshape_images(images)[55000:],define_classes(labels)[1][55000:],\n",
    "        transforms=transform)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=400,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=400,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "    classes = [str(i) for i in range(31)]\n",
    "    net = Net().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weight(define_classes(labels)[1][:55000]).to(\n",
    "        device))\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.025, weight_decay=0.01,\n",
    "        momentum=0.9)\n",
    "    \n",
    "    loss_train = []\n",
    "    loss_test = []\n",
    "    err_train = []\n",
    "    err_test = []\n",
    "    for epoch in range(nepochs):  # loop over the dataset multiple times\n",
    "        if epoch>15:\n",
    "            optimizer = optim.SGD(net.parameters(), lr=0.01,\n",
    "                weight_decay=0.01, momentum=0.9)\n",
    "        if epoch>25: #was30\n",
    "            optimizer = optim.SGD(net.parameters(), lr=0.005,\n",
    "                weight_decay=0.01, momentum=0.9)\n",
    "        if epoch>30: #was40\n",
    "            optimizer = optim.SGD(net.parameters(), lr=0.002,\n",
    "                weight_decay=0.01, momentum=0.9)\n",
    "        correct = 0.\n",
    "        total = 0.\n",
    "        running_loss_train = 0.0\n",
    "        running_loss_test = 0.0\n",
    "#        net.train()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            \n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs.to(device))\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss.item() / 55000\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "        err_train.append(1 - correct / total)\n",
    "\n",
    "        correct = 0.\n",
    "        total = 0.\n",
    "#        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images.to(device))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels.to(device)).sum().item()\n",
    "                loss = criterion(outputs, labels.to(device))\n",
    "                running_loss_test += loss.item() / 5000\n",
    "        err_test.append(1 - correct / total)\n",
    "        \n",
    "        loss_train.append(running_loss_train)\n",
    "        loss_test.append(running_loss_test)\n",
    "        print('Epoch: {}'.format(epoch))\n",
    "        print('Train loss: {0:.4f} Train error: {1:.2f}'.format(\n",
    "            loss_train[epoch], err_train[epoch]))\n",
    "        print('Test loss: {0:.4f} Test error: {1:.2f}'.format(\n",
    "            loss_test[epoch], err_test[epoch]))       \n",
    "    print('Finished Training')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "#    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 5000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "    class_correct = list(0. for i in range(31))\n",
    "    class_total = list(0. for i in range(31))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels.to(device)).squeeze()\n",
    "            for i in range(c.shape[0]):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    for i in range(31):\n",
    "        if class_total[i]!=0:\n",
    "            print('Accuracy of %5s : %2d %%' % (\n",
    "                classes[i], 100 * class_correct[i]/class_total[i]))\n",
    "        else:\n",
    "            print('Accuracy of %5s : %2d %%' % (\n",
    "                classes[i], 100 * class_correct[i]))\n",
    "    return net, loss_train, loss_test, err_train, err_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(labels):\n",
    "    scale = torch.FloatTensor(31)\n",
    "    for i in range(31):\n",
    "        scale[i] = ((labels==i).sum())\n",
    "    return scale.max() / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(images, labels):\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    for i in range(images.shape[0]):\n",
    "        image = images[i][1].reshape(100,100)\n",
    "        augmented_images.append(6*i)\n",
    "        augmented_images.append(image)\n",
    "        augmented_images.append(6*i+1)\n",
    "        augmented_images.append(np.flip(image, axis = 0))\n",
    "        augmented_images.append(6*i+2)\n",
    "        augmented_images.append(np.flip(image, axis = 1))\n",
    "        augmented_images.append(6*i+3)\n",
    "        augmented_images.append(np.transpose(image))\n",
    "        augmented_images.append(6*i+4)\n",
    "        augmented_images.append(scipy.ndimage.rotate(image, angle=3, reshape = False))\n",
    "        augmented_images.append(6*i+5)\n",
    "        augmented_images.append(scipy.ndimage.rotate(image, angle=-3, reshape = False))\n",
    "        augmented_labels.append((6*i  , labels[i][1]))\n",
    "        augmented_labels.append((6*i+1, labels[i][1]))\n",
    "        augmented_labels.append((6*i+2, labels[i][1]))\n",
    "        augmented_labels.append((6*i+3, labels[i][1]))\n",
    "        augmented_labels.append((6*i+4, labels[i][1]))\n",
    "        augmented_labels.append((6*i+5, labels[i][1]))\n",
    "    return np.array(augmented_images, dtype = object).reshape(-1, 2), np.array(augmented_labels, dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(images, labels):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(images[:,1])\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(labels[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A6XIWfxX9O2K"
   },
   "outputs": [],
   "source": [
    "train_labels = np.genfromtxt('train_labels.csv',names=True, delimiter=',', dtype=[('Id', 'i8'), ('Category', 'S5')])\n",
    "images_train = np.load('train_images.npy',encoding='latin1')\n",
    "\n",
    "#Augmentation des images\n",
    "augmented_images, augmented_labels = augment_data(images_train, train_labels)\n",
    "shuffle_data(augmented_images, augmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1070 Ti'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train loss: 0.0085 Train error: 0.95\n",
      "Test loss: 0.0084 Test error: 0.94\n",
      "Epoch: 1\n",
      "Train loss: 0.0078 Train error: 0.93\n",
      "Test loss: 0.0079 Test error: 0.89\n",
      "Epoch: 2\n",
      "Train loss: 0.0074 Train error: 0.89\n",
      "Test loss: 0.0072 Test error: 0.86\n",
      "Epoch: 3\n",
      "Train loss: 0.0068 Train error: 0.83\n",
      "Test loss: 0.0068 Test error: 0.80\n",
      "Epoch: 4\n",
      "Train loss: 0.0064 Train error: 0.78\n",
      "Test loss: 0.0065 Test error: 0.76\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.manual_seed(10)\n",
    "plt.style.use('ggplot')     \n",
    "plt.rc('xtick', labelsize=15)\n",
    "plt.rc('ytick', labelsize=15)\n",
    "plt.rc('axes', labelsize=15)\n",
    "\n",
    "nepochs = 40\n",
    "t1 = time.time()    \n",
    "net, loss_train, loss_test, e_train, e_test = train(augmented_images, augmented_labels, nepochs = nepochs)    \n",
    "print(time.time()-t1)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize = (20,10))\n",
    "ax1, ax2 = ax.flatten()\n",
    "\n",
    "ax1.plot(range(nepochs),loss_train, 'sk-', label='Train')\n",
    "ax1.plot(range(nepochs),loss_test, 'sr-', label='Valid')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Average cost')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(range(nepochs),e_train, 'sk-', label='Train')\n",
    "ax2.plot(range(nepochs),e_test, 'sr-', label='Valid')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Error')\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "kaggle.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
